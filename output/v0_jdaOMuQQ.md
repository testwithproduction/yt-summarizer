# Summary

In the technical talk, the speaker discussed Spark Connect's role in addressing issues related to version upgrades and managing Spark, aiming to facilitate non-JVM language bindings development. This leads to the upcoming release of Spark 4.0, which, while not announced at the conference, is expected later this year as part of an ongoing upstream open-source project.

Key highlights include:
1. **Spark Connect and NC SQL**: These features will become standard in Spark 4.0.
2. **Community Collaboration**: Emphasis on collaboration within the open-source community, particularly between compute (Apache Spark) and storage projects (Delta Lake, Apache Iceberg).
3. **Co-designing Features**: Certain features require integrated design across compute and storage stacks, necessitating collaboration among various projects.
4. **Preview Release**: Spark 4.0 preview has been released, providing a glimpse into the upcoming version. The community is encouraged to download, test, and provide feedback.

The talk underscores the spirit of open-source collaboration and the importance of community feedback in shaping the future of the Spark project.

# Transcription

 Now, with Spark Connect, it's really trying to solve this last two problems, version upgrades, managing Spark, make it easier to be building non-JBM language bindings. With that, it brings us to Spark 4.0. This is actually not a conference in which we will announce Spark 4.0's release today. It's actually an upstream open source project working at its own pace, but it is coming later this year. To give you a preview of some of the features, just similar to other major version, previous major version releases of Apache Psyche. There will be thousands of features that I can't possibly go all into today, but Spark Connect will GA and become the standard in Spark 4.0. NC SQL will become the standard in Spark 4.0. There's a lot of other features that we're looking forward to. But one thing I'm particularly excited about, definitely at this conference, is that the opportunity for the different open source community to be collaborating with each other, especially when it comes to compute and storage. So many, many features actually require code designing the compute stack, which is where Apache Spark comes in, as well as the storage stack, which is where Delta Lake, Linux Foundation, Delta Lake, and Apache Iceberg come in. As a matter of fact, many of the features you've heard about at this conference, at session talks, at keynotes, collisions, road tracking, merge performance, variant data type, Sean talked to you about, type widening. They are not just features in Delta or in Iceberg, but in Spark. They actually require co-thinking about all three projects for them to work. And this is sort of the radius of open source and the spirit of collaboration in open source. So last week, even though Spark 4.0 is not officially released yet, last week, the Apache Spark community have officially released Spark 4.0 preview. It's not the final release, but it gives you a glimpse into what Spark 4.0 would look like. Please go to the website, check it out, download it, give it a spin, and let us know your feedback. Thank you very much.