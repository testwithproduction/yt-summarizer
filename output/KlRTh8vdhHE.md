# Summary

Jackie Rossimer, Head of Platform Engineering for AI, Data, and Analytics at Block, outlines the company's journey in implementing AI to achieve real business impact through the Databricks platform. Block is composed of various decentralized business units, including Square, Cash App, Tidal, and TBD, all unified by the goal of economic empowerment. The challenge for the data platform team is to support these diverse units by delivering a flexible platform capable of handling both structured and unstructured data, and scaling to new use cases like generative AI.

Key Points:

1. **Diverse Business Units** 
    - Square: Supports small businesses in payments and banking.
    - Cash App: Facilitates peer-to-peer payments and financial management for consumers.
    - Tidal: A music streaming service aiding creators in monetizing their work.
    - TBD: Focuses on decentralized technologies like blockchain and Web3 identity.

2. **Flexible Data Platform Requirements**
    - Need to support both structured and unstructured data.
    - Must handle billions of transactions and scale for real-time data movement.

3. **Use Case: Generative AI for Square**
    - Automates small business onboarding and menu suggestions.
    - Saves up to 15% of time for small businesses, enhancing productivity and economic impact.

4. **Internal Productivity Boost**
    - Emphasis on code generation and workflow automation.
    - Leverages Databricks platform for scalable AI applications.

5. **Key Components of AI Platform**
    - Secure data stored in a federated data lake.
    - Utilizes Databricks AI platform, model serving, and ML flow for governance and developer experience.

6. **AI Strategy Pillars**
    - **Federation**: Consistent interfaces allowing model swaps.
    - **Agility**: Flexibility to evolve and scale with changing patterns.
    - **Control**: Maintaining data security and compliance, crucial for financial tech.

7. **Open Source & Proprietary Models**
    - Mosaic AI gateway facilitates model comparison (e.g., open source Lama vs proprietary GPT-4).
    - Fine-tuning and serving models within the Databricks platform to enhance security.
    - Implements RAG (retrieval-augmented generation) pattern for contextual relevance.

8. **Business Impact**
    - 26% reduction in time to deliver AI applications.
    - 32% increase in developer productivity.
    - $10 million in additional productivity gains.

Jackie concludes with an invitation to explore career opportunities at Block.

# Transcription

 Thank you, Casey. I'm Jackie Rossimer, and I'm the head of Platform Engineering for AI, Data, and Analytics at Block. Today, I'm going to tell you a little bit more about the journey we've had taking AI into real business impact using the Databricks platform. Unfortunately, I don't think my clicker is working. All right. Block is a really unique company because we have a bunch of decentralized business units that are all united by this common purpose of economic empowerment. We have Square, which is our first business unit where millions of small businesses leverage our products to take payments and grow their business through add-ons like banking. We have Cash App, where hundreds of millions of different consumers use our products to send payments to their friends and family, as well as manage their finances through products like investing and borrow. We have Tidal, which is a music streaming service founded by JZ that helps creators to monetize their creations. And we have TBD, which is a subsidiary working in decentralized technologies like blockchain and Web3 identity. One of the really unique challenges of our data platform team is that we have to have one data platform that's able to support all of these different diverse use cases, which also come with different people, culture, and practices. And so we have to make sure that we have a really flexible platform that can not only scale across these different types of data. We have billions of payments going through Square and Cash, so we have to really operate and scale when it comes to structured data moving in real time. We also have tons of unstructured data from Tidal, so we have to be able to handle both types. And it's really been a challenge to have a platform that's flexible enough to not only cover all of these use cases, but also be able to scale to new use cases that we didn't see coming like generative AI. Before we talk about the platform behind the scenes that allows us to productionize all these use cases, let's take a minute to look at one of these use cases in the wild. So here we have one of our generative AI use cases for Square, where we allow a small business to onboard and automatically get a suggested menu that can get them started right away without having to go through and manually fill in. One of the principles we've really tried to rely on as we think about how to use generative AI is this principle of giving time back. We want to give time back to our Square sellers so that they have a chance to focus on the parts of the business that really differentiate them, and we can automate away those non-differentiated business operations like onboarding or creating a menu. And so in this case, we've seen up to 15% time savings for small businesses to get set up and start making money. And with small businesses with really small margins, that can be a really, really huge advantage. Not only do we focus on generative AI for a lot of these external facing use cases, but we also have a really big emphasis on internal facing productivity use cases, like code generation and workflow automation. And we all power these use cases through this flexible Databricks platform that we're going to talk through in a little bit more detail now. We wanted to build our AI platform in a really flexible, scalable way where the data was already securely stored in this federated data lake that connects data across the BUs, business units, while still allowing those business units to implement their own security policies and access controls. We were able to quickly and seamlessly stand up a large language model platform on top of our existing Databricks infrastructure rather than having to start from scratch because of the composability of this platform, where different business units can use some parts of it, but not all parts of it. Key components of our platform that we've been able to leverage for the large language model use cases is the Databricks AI platform and model serving, which allows us to manage calls from all model end points, as well as ML flow for large language model operations and governance, which is a huge developer experience advantage, since many of our machine learning engineers are already familiar with ML flow. Because of both the complexity of our different business use cases and the quickly evolving external landscape, we have centered our AI strategy around supporting production quality use cases for AI, while assuming that the models are going to completely change over the next few years. Our strategy has three key pillars. First of all, we center federation, the idea that we want this consistent interface that we can swap models out behind as the models continue to evolve. We also really center this idea of agility, where we know that the patterns that we're using to call models today are not necessarily the patterns that we want to use to call models tomorrow, and so we want our platform to be able to evolve and scale to support that. And then finally, we really center this idea of control. As a financial technology company, we have a lot of really sensitive enterprise data that we want to make sure is staying secure as we use it for new use cases like large language models. As innovation continues to happen in the generative AI space, and new models get released, we want to keep this optionality to easily switch out these models without having to write a whole bunch of new code. For instance, our company's philosophy is really aligned with open source, but a lot of our original use cases have used proprietary models like GPT-4. With the Databricks Mosaic AI gateway, we can really easily compare the Lama open source models to OpenAI's closed source models, and match the same easy developer experience without having the need to implement new APIs. This federated approach ensures that we stay agile and responsive to advancements in AI technology. While most of our original use cases use state-of-the-art models like GPT-4, we're increasingly seeing that we have really specific use cases where we want to fine-tune open source models using proprietary data. With Mosaic AI training and Databricks, we can easily fine-tune these open source models in the same place within the platform. And most importantly, that means that the data doesn't have to leave the platform, which would be an additional security risk. And then once this model is fine-tuned, we can easily serve it through that same AI gateway. Finally, for most of our use cases, we don't just use a model, but we use this rag pattern that was mentioned earlier, where we're sending a lot of context along with that model to make sure that we get the best and most relevant results. With Mosaic AI, we can easily implement this rag pattern right within the platform with the full and controlled governance of components like Unity Catalog and not have to worry about the data leaving the platform. This centralized approach really is important for our security posture to make sure that we can have the right granular access, as well as centralized concerns like compliance and cost optimization, which can become really sprawling if we have a bunch of different decentralized endpoints. Using our flexible platform, we've been able to see real change in metrics that directly impact the business. We've seen a 26% improvement in the time that it takes to deliver a generative AI application to production. We've seen a 32% increase in developer productivity with engineers who are using the platform. And all of that has added up to around $10 million in additional productivity gain versus our original forecasts. Thank you. And if you're interested in joining, please check out our career page.