# Summary

The speaker introduced and discussed DucDB, a small in-process analytical data management system that speaks SQL and has zero dependencies. Key highlights from the talk include:

- **Introduction to DucDB**: DucDB is a lightweight system for data management, suitable for tasks too large for Excel but too small for systems like Spark. It was initially introduced last year on the same stage, and since then, adoption has grown significantly, illustrated by nearly doubling GitHub stars to almost 20,000.

- **Release of DucDB 1.0**: The recent release of version 1.0 marks a major milestone, featuring a stable SQL dialect, various APIs, and backward-compatible storage formats. This completion comes after six years of R&D.

- **DucDB in the Ecosystem**: DucDB is positioned for the "last mile" of data analysis, acting as a bridge for data processed by larger systems like Spark, typically using Parquet files.

- **Delta Lake Integration**: The speaker announced official DucDB support for Delta Lake, enhancing data interoperability with Spark. The integration leverages the Delta kernel, enabling efficient Delta file operations without building from scratch.

- **Unity Catalog Extension**: A new extension allows DucDB to interact with Delta Lake tables in the Unity catalog, simplifying access and operations on these tables.

- **Growing List of Extensions**: DucDB now supports various extensions, including iceberg, vector search, and spatial. The community is encouraged to contribute to DucDB extensions.

- **Community Extensions Launch**: The speaker announced the launch of community extensions, allowing users to create, publish, and easily install DucDB extensions.

The talk concluded with a mention of a subsequent talk scheduled for that afternoon for those interested in learning more about DucDB's new features and integrations.

# Transcription

 Hey, thank you so much. Yes, hello and very good morning. It's wonderful to see all of you here. I have to adjust my eyes a bit to the amount of people. As Chante said, I'm one of the people behind DucDB. So for those of you who do not know what is DucDB, it's a small in-process analytical data management system, speak SQL, has zero dependencies. And I'm having a lot of fun working on it with a growing team. And last year, I talked about DucDB on this very stage for the first time, and it was very exciting. But also, lots of things have happened since then in DucDB land. There's been an incredible growth in adoption for DucDB. We're seeing all sorts of crazy things. And here, as an example, it's just the stars on GitHub have doubled within a year to almost 20,000. And in fact, we are so close to 20,000. So if you want to like it today, then maybe we'll beat it. But what also happened, and just last week, we actually released DucDB 1.0. And that was a big moment for us. It was the culmination of six years of R&D in data management systems. And what does 1.0 mean? It means that we have now a stable SQL dialect and various APIs. And most importantly, our storage format for DucDB is going to be backwards compatible from now on out. But maybe taking a little bit of step back, how does DucDB fit in the general ecosystem? If we look at the world's most widely used data tools, Excel. And we look at very capable system like Spark. There's still a pretty big gap. There's a lot of data sets that are not going to work in Excel. But they are maybe a bit too small to actually throw Spark at them. So DucDB is really perfect for this last mile of data analysis, where you may not need a whole data center to compute something. So for example, you have already gone through your log files in Spark. And now it's time to do some last mile analysis with DucDB, doing some plots, what have you. That's where DucDB fits into this big picture. But now we have to somehow get the data between Spark from Spark to DucDB. So how are we going to do that? Obviously, we're going to use the best tool for the job available, right? CSV files. Maybe not. So typically, people use Parquet files for this. Obviously, both Spark and DucDB can read and write Parquet files. So that works really well. But we've all heard about the issues that have appeared with updates and schema evolution, these kind of things, which is why we have Lakehouse formats. So today, we are announcing official DucDB support for Delta Lake. It's going to be available completely out of the box with zero configuration or anything like that. But we have done a bunch of these integrations. And one thing that's really special about the Delta Lake integration is that we use this Delta kernel that Databricks is building with the community. And that's really exciting because it means that we don't have to build this from scratch, like we used to, for example, with the Parquet reader. But we can actually delegate a lot of the hard work of reading Delta files to the Delta kernel while at the same time keeping our operators within the engine and so on and so forth. So it's really exciting. We also made an extension for DucDB that can talk to the Unity catalog. So with this extension, we can find the Delta Lake tables in the catalog and then actually interact with them from DucDB itself. So here, we can see a script that actually works if you install DucDB now. You can install this Unity catalog extension. You can create your secret, which is credentials. And then you can basically just read these tables as if they were local tables. If you want to hear more about this, there's actually going to be a talk this afternoon at 1.40. Just look for DucDB in the title. So the Delta extension joins this growing list of DucDB extensions. For example, there's others for iceberg, vector search, spatial, and this sort of thing. But as an open source project and a small team, we're really excited about Tabular and Databricks being in Delta Lake and iceberg closer together because for us, it means we don't have to maintain two different things for the same, essentially, problem. And we're really excited about that. Means less work for us and I think everyone wins. Just want to plug one sort of small thing that we're actually launching today. I've mentioned extensions to DucDB. We've seen a lot of uptake in DucDB extensions. And from now on, actually, we are launching community extensions, which means that everyone can make DucDB extensions and basically publish them and then installing them as easy as just typing install into a DucDB near you. So that's all for today. Thank you very much and I will give back to Sean. Thanks. Thank you. Thanks. Thanks. Thanks. Thanks.